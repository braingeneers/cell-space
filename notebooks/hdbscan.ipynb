{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDBSCAN\n",
    "Evaluate HDBSCAN as a non-parametric clustering algorithm\n",
    "\n",
    "## References\n",
    "[How HDBSCAN Works](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html)\n",
    "\n",
    "[Grok Chat](https://grok.com/share/bGVnYWN5_cdb89d47-1ebf-4821-9f2f-d7d1563010e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q hdbscan scikit-learn numpy onnx skl2onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.datasets import make_blobs  # For dummy data; replace with your RNA-seq encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Predict labels and encodings for training and test sets for a SIMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions and encodings for checkpoints/allen-celltypes+human-cortex+various-cortical-areas.h5ad using model public/models/allen-celltypes+human-cortex+various-cortical-areas.onnx\n",
      "2162 genes in the sample and not in the model\n",
      "Processing 1000 cells with batch size 32\n",
      "100%|██████████████████████████████████████| 1000/1000 [00:03<00:00, 326.66it/s]\n",
      "Saved encodings to checkpoints/allen-celltypes+human-cortex+various-cortical-areas-encodings.npy\n",
      "Saved predictions to checkpoints/allen-celltypes+human-cortex+various-cortical-areas-predictions.npy\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python scripts/cluster.py predict  \\\n",
    "    public/models/allen-celltypes+human-cortex+various-cortical-areas.onnx \\\n",
    "    checkpoints/allen-celltypes+human-cortex+various-cortical-areas.h5ad \\\n",
    "    --num-samples 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions and encodings for data/allen-celltypes+human-cortex+m1.h5ad using model public/models/allen-celltypes+human-cortex+various-cortical-areas.onnx\n",
      "2162 genes in the sample and not in the model\n",
      "Processing 1000 cells with batch size 32\n",
      "100%|██████████████████████████████████████| 1000/1000 [00:03<00:00, 324.24it/s]\n",
      "Saved encodings to data/allen-celltypes+human-cortex+m1-encodings.npy\n",
      "Saved predictions to data/allen-celltypes+human-cortex+m1-predictions.npy\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python scripts/cluster.py predict  \\\n",
    "    public/models/allen-celltypes+human-cortex+various-cortical-areas.onnx \\\n",
    "    data/allen-celltypes+human-cortex+m1.h5ad \\\n",
    "    --num-samples 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"../checkpoints/allen-celltypes+human-cortex+various-cortical-areas-encodings.npy\")\n",
    "Y_train = np.load(\"../checkpoints/allen-celltypes+human-cortex+various-cortical-areas-predictions.npy\")\n",
    "\n",
    "X_test = np.load(\"../data/allen-celltypes+human-cortex+m1-encodings.npy\")\n",
    "Y_test = np.load(\"../data/allen-celltypes+human-cortex+m1-predictions.npy\")\n",
    "\n",
    "\n",
    "with open(\"../public/models/allen-celltypes+human-cortex+various-cortical-areas.classes\", \"r\") as f:\n",
    "    labels = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters found: 3\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train HDBSCAN on the training set for this model\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=100,  # Minimum size of clusters; tune based on your data\n",
    "    min_samples=100,       # Controls noise sensitivity; tune as needed\n",
    "    prediction_data=True # Required for approximate_predict\n",
    ")\n",
    "hdbscan_model.fit(X_train)\n",
    "\n",
    "# Get cluster labels for training data\n",
    "train_labels = hdbscan_model.labels_\n",
    "print(f\"Number of clusters found: {len(np.unique(train_labels)) - (1 if -1 in train_labels else 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters found: 2\n"
     ]
    }
   ],
   "source": [
    "# Predict clusters for new data without retraining\n",
    "from hdbscan import approximate_predict\n",
    "test_labels, strengths = approximate_predict(hdbscan_model, X_test)\n",
    "\n",
    "print(f\"Number of clusters found: {len(np.unique(test_labels)) - (1 if -1 in test_labels else 0)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
