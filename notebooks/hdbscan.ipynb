{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDBSCAN\n",
    "Evaluate HDBSCAN as a non-parametric clustering algorithm\n",
    "\n",
    "## References\n",
    "[How HDBSCAN Works](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html)\n",
    "\n",
    "[Grok Chat](https://grok.com/share/bGVnYWN5_cdb89d47-1ebf-4821-9f2f-d7d1563010e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q hdbscan scikit-learn numpy onnx skl2onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.datasets import make_blobs  # For dummy data; replace with your RNA-seq encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest\n",
    "Predict labels and encodings for training and test sets for a SIMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions and encodings for checkpoints/allen-celltypes+human-cortex+various-cortical-areas.h5ad using model public/models/allen-celltypes+human-cortex+various-cortical-areas.onnx\n",
      "2162 genes in the sample and not in the model\n",
      "Processing 1000 cells with batch size 32\n",
      "100%|██████████████████████████████████████| 1000/1000 [00:03<00:00, 326.66it/s]\n",
      "Saved encodings to checkpoints/allen-celltypes+human-cortex+various-cortical-areas-encodings.npy\n",
      "Saved predictions to checkpoints/allen-celltypes+human-cortex+various-cortical-areas-predictions.npy\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python scripts/cluster.py predict  \\\n",
    "    public/models/allen-celltypes+human-cortex+various-cortical-areas.onnx \\\n",
    "    checkpoints/allen-celltypes+human-cortex+various-cortical-areas.h5ad \\\n",
    "    --num-samples 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions and encodings for data/allen-celltypes+human-cortex+m1.h5ad using model public/models/allen-celltypes+human-cortex+various-cortical-areas.onnx\n",
      "2162 genes in the sample and not in the model\n",
      "Processing 1000 cells with batch size 32\n",
      "100%|██████████████████████████████████████| 1000/1000 [00:03<00:00, 324.24it/s]\n",
      "Saved encodings to data/allen-celltypes+human-cortex+m1-encodings.npy\n",
      "Saved predictions to data/allen-celltypes+human-cortex+m1-predictions.npy\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python scripts/cluster.py predict  \\\n",
    "    public/models/allen-celltypes+human-cortex+various-cortical-areas.onnx \\\n",
    "    data/allen-celltypes+human-cortex+m1.h5ad \\\n",
    "    --num-samples 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"../checkpoints/allen-celltypes+human-cortex+various-cortical-areas-encodings.npy\")\n",
    "Y_train = np.load(\"../checkpoints/allen-celltypes+human-cortex+various-cortical-areas-predictions.npy\")\n",
    "\n",
    "X_test = np.load(\"../data/allen-celltypes+human-cortex+m1-encodings.npy\")\n",
    "Y_test = np.load(\"../data/allen-celltypes+human-cortex+m1-predictions.npy\")\n",
    "\n",
    "\n",
    "with open(\"../public/models/allen-celltypes+human-cortex+various-cortical-areas.classes\", \"r\") as f:\n",
    "    labels = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters found: 3\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train HDBSCAN on the training set for this model\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=100,  # Minimum size of clusters; tune based on your data\n",
    "    min_samples=100,       # Controls noise sensitivity; tune as needed\n",
    "    prediction_data=True # Required for approximate_predict\n",
    ")\n",
    "hdbscan_model.fit(X_train)\n",
    "\n",
    "# Get cluster labels for training data\n",
    "train_labels = hdbscan_model.labels_\n",
    "print(f\"Number of clusters found: {len(np.unique(train_labels)) - (1 if -1 in train_labels else 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters found: 2\n"
     ]
    }
   ],
   "source": [
    "# Predict clusters for new data without retraining\n",
    "from hdbscan import approximate_predict\n",
    "test_labels, strengths = approximate_predict(hdbscan_model, X_test)\n",
    "\n",
    "print(f\"Number of clusters found: {len(np.unique(test_labels)) - (1 if -1 in test_labels else 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n",
    "Attempt to export the trained hdbscan model to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for ONNX conversion\n",
    "import skl2onnx\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import onnxruntime as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingShapeCalculator",
     "evalue": "Unable to find a shape calculator for type '<class 'hdbscan.hdbscan_.HDBSCAN'>'.\nIt usually means the pipeline being converted contains a\ntransformer or a predictor with no corresponding converter\nimplemented in sklearn-onnx. If the converted is implemented\nin another library, you need to register\nthe converted so that it can be used by sklearn-onnx (function\nupdate_registered_converter). If the model is not yet covered\nby sklearn-onnx, you may raise an issue to\nhttps://github.com/onnx/sklearn-onnx/issues\nto get the converter implemented or even contribute to the\nproject. If the model is a custom model, a new converter must\nbe implemented. Examples can be found in the gallery.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingShapeCalculator\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m input_type \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m, FloatTensorType([\u001b[38;5;28;01mNone\u001b[39;00m, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]]))]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Convert the HDBSCAN model to ONNX format\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m \u001b[43mskl2onnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_sklearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhdbscan_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhdbscan_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzipmap\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Save the ONNX model to a file\u001b[39;00m\n\u001b[1;32m     13\u001b[0m onnx_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/hdbscan_model.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/cell-space/venv/lib/python3.10/site-packages/skl2onnx/convert.py:210\u001b[0m, in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate, white_op, black_op, final_types, dtype, naming, model_optim, verbose)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[convert_sklearn] convert_topology\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 210\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_topology\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopology\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoc_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_opset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_identity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_optim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[convert_sklearn] end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/cell-space/venv/lib/python3.10/site-packages/skl2onnx/common/_topology.py:1528\u001b[0m, in \u001b[0;36mconvert_topology\u001b[0;34m(topology, model_name, doc_string, target_opset, options, remove_identity, verbose)\u001b[0m\n\u001b[1;32m   1517\u001b[0m container \u001b[38;5;241m=\u001b[39m ModelComponentContainer(\n\u001b[1;32m   1518\u001b[0m     target_opset,\n\u001b[1;32m   1519\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1523\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   1524\u001b[0m )\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;66;03m# Traverse the graph from roots to leaves\u001b[39;00m\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;66;03m# This loop could eventually be parallelized.\u001b[39;00m\n\u001b[0;32m-> 1528\u001b[0m \u001b[43mtopology\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_operators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m container\u001b[38;5;241m.\u001b[39mensure_topological_order()\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(container\u001b[38;5;241m.\u001b[39minputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/cell-space/venv/lib/python3.10/site-packages/skl2onnx/common/_topology.py:1344\u001b[0m, in \u001b[0;36mTopology.convert_operators\u001b[0;34m(self, container, verbose)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m operator\u001b[38;5;241m.\u001b[39moutputs:\n\u001b[1;32m   1342\u001b[0m     _check_variable_out_(variable, operator)\n\u001b[0;32m-> 1344\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_shape_calculator\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_converter(operator, container, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;66;03m# If an operator contains a sequence of operators,\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;66;03m# output variables are not necessarily known at this stage.\u001b[39;00m\n",
      "File \u001b[0;32m~/cell-space/venv/lib/python3.10/site-packages/skl2onnx/common/_topology.py:1159\u001b[0m, in \u001b[0;36mTopology.call_shape_calculator\u001b[0;34m(self, operator)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1158\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Shape2] call infer_types for \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, operator)\n\u001b[0;32m-> 1159\u001b[0m     \u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cell-space/venv/lib/python3.10/site-packages/skl2onnx/common/_topology.py:625\u001b[0m, in \u001b[0;36mOperator.infer_types\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer_types\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;66;03m# Invoke a core inference function\u001b[39;00m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 625\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MissingShapeCalculator(\n\u001b[1;32m    626\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a shape calculator for type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    627\u001b[0m                 \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_operator)\n\u001b[1;32m    628\u001b[0m             )\n\u001b[1;32m    629\u001b[0m         )\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m         shape_calc \u001b[38;5;241m=\u001b[39m _registration\u001b[38;5;241m.\u001b[39mget_shape_calculator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype)\n",
      "\u001b[0;31mMissingShapeCalculator\u001b[0m: Unable to find a shape calculator for type '<class 'hdbscan.hdbscan_.HDBSCAN'>'.\nIt usually means the pipeline being converted contains a\ntransformer or a predictor with no corresponding converter\nimplemented in sklearn-onnx. If the converted is implemented\nin another library, you need to register\nthe converted so that it can be used by sklearn-onnx (function\nupdate_registered_converter). If the model is not yet covered\nby sklearn-onnx, you may raise an issue to\nhttps://github.com/onnx/sklearn-onnx/issues\nto get the converter implemented or even contribute to the\nproject. If the model is a custom model, a new converter must\nbe implemented. Examples can be found in the gallery.\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape for the ONNX model\n",
    "# X_train.shape[1] represents the number of features in your input data\n",
    "input_type = [('input', FloatTensorType([None, X_train.shape[1]]))]\n",
    "\n",
    "# Convert the HDBSCAN model to ONNX format\n",
    "onnx_model = skl2onnx.convert_sklearn(\n",
    "    hdbscan_model, \n",
    "    initial_types=input_type,\n",
    "    options={id(hdbscan_model): {'zipmap': False}}\n",
    ")\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "onnx_model_path = \"../models/hdbscan_model.onnx\"\n",
    "with open(onnx_model_path, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(f\"ONNX model saved to {onnx_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'direct_ops' from 'onnxconverter_common' (/Users/rcurrie/cell-space/venv/lib/python3.10/site-packages/onnxconverter_common/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskl2onnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m update_registered_converter\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskl2onnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshape_calculator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m calculate_linear_classifier_output_shapes\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnxconverter_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m direct_ops\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhdbscan_shape_calculator\u001b[39m(operator):\n\u001b[1;32m      6\u001b[0m     calculate_linear_classifier_output_shapes(operator)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'direct_ops' from 'onnxconverter_common' (/Users/rcurrie/cell-space/venv/lib/python3.10/site-packages/onnxconverter_common/__init__.py)"
     ]
    }
   ],
   "source": [
    "from skl2onnx import update_registered_converter\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes\n",
    "from onnxconverter_common import direct_ops\n",
    "\n",
    "def hdbscan_shape_calculator(operator):\n",
    "    calculate_linear_classifier_output_shapes(operator)\n",
    "\n",
    "def hdbscan_converter(scope, operator, container):\n",
    "    # This is a simplified converter - actual implementation would need to match HDBSCAN's logic\n",
    "    X = operator.inputs[0]\n",
    "    output = operator.outputs[0]\n",
    "    \n",
    "    # Add basic operations (this would need to be expanded for full HDBSCAN functionality)\n",
    "    direct_ops.add_identity(container, X, output.name)\n",
    "\n",
    "# Register the custom converter\n",
    "update_registered_converter(\n",
    "    HDBSCAN,\n",
    "    \"CustomHDBSCAN\",\n",
    "    hdbscan_shape_calculator,\n",
    "    hdbscan_converter\n",
    ")\n",
    "\n",
    "# Then try the conversion again\n",
    "onnx_model = convert_sklearn(\n",
    "    hdbscan_model,\n",
    "    \"hdbscan_model\",\n",
    "    initial_types=initial_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxconverter_common"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
